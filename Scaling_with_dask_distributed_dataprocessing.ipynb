{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Load Statistics ---\n",
      "Mean Load: 30.00\n",
      "Standard Deviation of Load: 11.66\n",
      "\n",
      "--- High Utilization Hospitals ---\n",
      "     HospitalID  Capacity  CurrentLoad  \\\n",
      "15           16        52           46   \n",
      "64           65        53           46   \n",
      "106         107        60           49   \n",
      "119         120        57           49   \n",
      "120         121        61           49   \n",
      "\n",
      "                                    Location  Utilization  \n",
      "15   (43.70993846046142, -79.52076546167815)     0.884615  \n",
      "64   (43.74903005765775, -79.40244289595702)     0.867925  \n",
      "106   (43.87917856439317, -79.5767267204229)     0.816667  \n",
      "119  (43.643912197648675, -79.5264931155417)     0.859649  \n",
      "120   (43.62045169281565, -79.5948376186101)     0.803279  \n",
      "\n",
      "--- Aggregated Statistics by Location Clusters ---\n",
      "             Capacity  CurrentLoad\n",
      "Cluster                           \n",
      "Cluster_438     24168        10023\n",
      "Cluster_437     26605        10007\n",
      "Cluster_436     24057         9968\n",
      "\n",
      "High-utilization hospitals saved to 'high_utilization_hospitals.csv'.\n",
      "\n",
      "Lazy computation object: dd.Scalar<series-..., dtype=int64>\n",
      "Total Load: 29998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JEFFEYMARKUS/miniforge3/lib/python3.12/site-packages/dask/dataframe/__init__.py:49: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate large-scale hospital data\n",
    "large_hospital_data = pd.DataFrame({\n",
    "    \"HospitalID\": range(1, 1001),  # Unique hospital IDs\n",
    "    \"Capacity\": np.random.randint(50, 100, 1000),  # Random capacities between 50 and 100\n",
    "    \"CurrentLoad\": np.random.randint(10, 50, 1000),  # Random current loads between 10 and 50\n",
    "    \"Location\": [(np.random.uniform(43.6, 43.9), np.random.uniform(-79.6, -79.4)) for _ in range(1000)]  # Random lat/lon\n",
    "})\n",
    "\n",
    "# Convert Pandas DataFrame to Dask DataFrame\n",
    "ddf = dd.from_pandas(large_hospital_data, npartitions=10)  # Split into 10 partitions for distributed processing\n",
    "\n",
    "# Example 1: Calculate mean and standard deviation of current load\n",
    "mean_load = ddf[\"CurrentLoad\"].mean().compute()  # Compute mean of \"CurrentLoad\"\n",
    "std_load = ddf[\"CurrentLoad\"].std().compute()  # Compute standard deviation of \"CurrentLoad\"\n",
    "print(\"\\n--- Load Statistics ---\")\n",
    "print(f\"Mean Load: {mean_load:.2f}\")\n",
    "print(f\"Standard Deviation of Load: {std_load:.2f}\")\n",
    "\n",
    "# Example 2: Filter hospitals with high utilization (CurrentLoad / Capacity > 0.75)\n",
    "ddf[\"Utilization\"] = ddf[\"CurrentLoad\"] / ddf[\"Capacity\"]\n",
    "high_utilization_hospitals = ddf[ddf[\"Utilization\"] > 0.75]\n",
    "print(\"\\n--- High Utilization Hospitals ---\")\n",
    "print(high_utilization_hospitals.compute().head())  # Compute and display a few rows\n",
    "\n",
    "# Example 3: Aggregations - Total capacity and load by location clusters\n",
    "# Simulate location clusters for aggregation\n",
    "ddf[\"Cluster\"] = ddf[\"Location\"].apply(lambda loc: f\"Cluster_{int(loc[0] * 10)}\", meta=(\"Location\", str))\n",
    "aggregated_stats = ddf.groupby(\"Cluster\").agg({\n",
    "    \"Capacity\": \"sum\",\n",
    "    \"CurrentLoad\": \"sum\"\n",
    "}).compute()\n",
    "print(\"\\n--- Aggregated Statistics by Location Clusters ---\")\n",
    "print(aggregated_stats)\n",
    "\n",
    "# Example 4: Export filtered data\n",
    "# Save high-utilization hospitals to a CSV file (parallel write using Dask)\n",
    "high_utilization_hospitals.to_csv(\"high_utilization_hospitals_*.csv\", index=False, single_file=True)\n",
    "print(\"\\nHigh-utilization hospitals saved to 'high_utilization_hospitals.csv'.\")\n",
    "\n",
    "# Example 5: Perform lazy computations\n",
    "# Demonstrating Dask's lazy evaluation capabilities\n",
    "lazy_computation = ddf[\"CurrentLoad\"].sum()  # No computation happens here\n",
    "print(\"\\nLazy computation object:\", lazy_computation)  # Shows a Dask computation graph\n",
    "total_load = lazy_computation.compute()  # Actual computation triggered\n",
    "print(\"Total Load:\", total_load)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
