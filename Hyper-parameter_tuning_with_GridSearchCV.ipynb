{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 27 candidates, totalling 54 fits\n",
      "\n",
      "--- Hyperparameter Tuning Results ---\n",
      "Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best Cross-Validation MSE: 397.9200000000001\n",
      "Test Set MSE: 153.75999999999996\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Sample dataset\n",
    "data = pd.DataFrame({\n",
    "    \"CapacityUtilization\": [0.8, 0.6, 0.9, 0.4],\n",
    "    \"DayOfWeek\": [1, 3, 4, 5],\n",
    "    \"HistoricalWaitTime\": [30, 45, 20, 60],\n",
    "    \"WaitTime\": [35, 50, 25, 55]\n",
    "})\n",
    "\n",
    "# Define features and target\n",
    "features = data[[\"CapacityUtilization\", \"DayOfWeek\", \"HistoricalWaitTime\"]]\n",
    "target = data[\"WaitTime\"]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the Random Forest model and hyperparameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],  # Number of trees in the forest\n",
    "    \"max_depth\": [None, 10, 20],  # Maximum depth of the tree\n",
    "    \"min_samples_split\": [2, 5, 10]  # Minimum number of samples required to split an internal node\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=42),  # Base estimator\n",
    "    param_grid=param_grid,  # Parameter grid to search\n",
    "    cv=2,  # 5-fold cross-validation\n",
    "    scoring=\"neg_mean_squared_error\",  # Scoring metric to evaluate performance\n",
    "    verbose=1,  # Print progress during grid search\n",
    "    n_jobs=-1  # Use all available CPU cores for faster processing\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Extract best parameters and score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_  # Convert negative MSE to positive for interpretability\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "test_predictions = best_model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, test_predictions)\n",
    "\n",
    "# Output results\n",
    "print(\"\\n--- Hyperparameter Tuning Results ---\")\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Cross-Validation MSE:\", best_score)\n",
    "print(\"Test Set MSE:\", test_mse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
